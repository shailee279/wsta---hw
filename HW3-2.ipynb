{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JTSoilFW5rOs"
   },
   "source": [
    "# Homework 3: Language Modelling in Hangman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "4q7up1aP5rOu"
   },
   "source": [
    "Student Name:  Swapnil Shailee\n",
    "\n",
    "Student ID:  952247"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3a5JLBpb5rOw"
   },
   "source": [
    "## General info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hbgIekbT5rOx"
   },
   "source": [
    "<b>Due date</b>:  Friday, 17 May 2019 4pm\n",
    "\n",
    "<b>Submission method</b>: see LMS\n",
    "\n",
    "<b>Submission materials</b>: completed copy of this iPython notebook\n",
    "\n",
    "<b>Late submissions</b>: -20% per day\n",
    "\n",
    "<b>Marks</b>: 7% of mark for class (with 6% on correctness + 1% on quality and efficiency of your code)\n",
    "\n",
    "<b>Materials</b>: See the main class LMS page for information on the basic setup required for this class, including an iPython notebook viewer and the python packages NLTK, Numpy, Scipy, Matplotlib and Scikit-Learn. In particular, if you are not using a lab computer which already has it installed, we recommend installing all the data for NLTK, since you will need various parts of it to complete this assignment. You can also use any Python built-in packages, but do not use any other 3rd party packages; if your iPython notebook doesn't run on the marker's machine, you will lose marks. <b> You should use Python 3</b>. \n",
    "\n",
    "To familiarize yourself with NLTK, here is a free online book:  Steven Bird, Ewan Klein, and Edward Loper (2009). <a href=http://nltk.org/book>Natural Language Processing with Python</a>. O'Reilly Media Inc. You may also consult the <a href=https://www.nltk.org/api/nltk.html>NLTK API</a>.\n",
    "\n",
    "<b>Evaluation</b>: Your iPython notebook should run end-to-end without any errors in a reasonable amount of time, and you must follow all instructions provided below, including specific implementation requirements and instructions for what needs to be printed (please avoid printing output we don't ask for). You should edit the sections below where requested, but leave the rest of the code as is. You should leave the output from running your code in the iPython notebook you submit, to assist with marking. The amount each section is worth is given in parenthesis after the instructions. \n",
    "\n",
    "You will be marked not only on the correctness of your methods, but also the quality and efficency of your code: in particular, you should be careful to use Python built-in functions and operators when appropriate and pick descriptive variable names that adhere to <a href=\"https://www.python.org/dev/peps/pep-0008/\">Python style requirements</a>. If you think it might be unclear what you are doing, you should comment your code to help the marker make sense of it.\n",
    "\n",
    "<b>Updates</b>: Any major changes to the assignment will be announced via LMS. Minor changes and clarifications will be announced in the forum on LMS, we recommend you check the forum regularly.\n",
    "\n",
    "<b>Academic Misconduct</b>: For most people, collaboration will form a natural part of the undertaking of this homework, and we encourge you to discuss it in general terms with other students. However, this ultimately is still an individual task, and so reuse of code or other instances of clear influence will be considered cheating. We will be checking submissions for originality and will invoke the University’s <a href=\"http://academichonesty.unimelb.edu.au/policy.html\">Academic Misconduct policy</a> where inappropriate levels of collusion or plagiarism are deemed to have taken place.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kHP4wz6I5rO0"
   },
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xaJiY0RG5rO1"
   },
   "source": [
    "In this homework, you'll be creating an 'artificial intelligence' player for the classic Hangman word guessing game. You will need to implement several different automatic strategies based on character level language models. Your objective is to create an automatic player which makes the fewest mistakes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_XL-pMcj5rO2"
   },
   "source": [
    "## The Hangman Game (*No implementation is needed*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T0u2-Dtz5rO2"
   },
   "source": [
    "The <a href=\"https://en.wikipedia.org/wiki/Hangman_(game)\">Hangman game</a> is a simple game whereby one person thinks of a word, which they keep secret from their opponent, who tries to guess the word one character at a time. The game ends when the opponent makes more than a fixed number of incorrect guesses, or they figure out the secret word before then (in which case they *win*). \n",
    "\n",
    "Here's a simple version of the game. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a5nFvXMF5rO4"
   },
   "outputs": [],
   "source": [
    "def hangman(secret_word, guesser, max_mistakes=8, verbose=True, **guesser_args):\n",
    "    \"\"\"\n",
    "        This function plays the hangman game with the provided gusser and returns the number of incorrect guesses. \n",
    "        \n",
    "        secret_word: a string of lower-case alphabetic characters, i.e., the answer to the game\n",
    "        guesser: a function which guesses the next character at each stage in the game\n",
    "            The function takes a:\n",
    "                mask: what is known of the word, as a string with _ denoting an unknown character\n",
    "                guessed: the set of characters which already been guessed in the game\n",
    "                guesser_args: additional (optional) keyword arguments, i.e., name=value\n",
    "        max_mistakes: limit on length of game, in terms of allowed mistakes\n",
    "        verbose: be chatty vs silent\n",
    "        guesser_args: keyword arguments to pass directly to the guesser function\n",
    "    \"\"\"\n",
    "    secret_word = secret_word.lower()\n",
    "    mask = ['_'] * len(secret_word)\n",
    "    guessed = set()\n",
    "    if verbose:\n",
    "        print(\"Starting hangman game. Target is\", ' '.join(mask), 'length', len(secret_word))\n",
    "    \n",
    "    mistakes = 0\n",
    "    while mistakes < max_mistakes:\n",
    "        if verbose:\n",
    "            print(\"You have\", (max_mistakes-mistakes), \"attempts remaining.\")\n",
    "        guess = guesser(mask, guessed, **guesser_args)\n",
    "\n",
    "        if verbose:\n",
    "            print('Guess is', guess)\n",
    "        if guess in guessed:\n",
    "            if verbose:\n",
    "                print('Already guessed this before.')\n",
    "            mistakes += 1\n",
    "        else:\n",
    "            guessed.add(guess)\n",
    "            if guess in secret_word:\n",
    "                for i, c in enumerate(secret_word):\n",
    "                    if c == guess:\n",
    "                        mask[i] = c\n",
    "                if verbose:\n",
    "                    print('Good guess:', ' '.join(mask))\n",
    "            else:\n",
    "                if verbose:\n",
    "                    print('Sorry, try again.')\n",
    "                mistakes += 1\n",
    "                \n",
    "        if '_' not in mask:\n",
    "            if verbose:\n",
    "                print('Congratulations, you won.')\n",
    "            return mistakes\n",
    "        \n",
    "    if verbose:\n",
    "        print('Out of guesses. The word was', secret_word)    \n",
    "    return mistakes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RrQp2amr5rO8"
   },
   "source": [
    "Here is a human guesser allowing interactive play."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cZrtBtjf5rO9"
   },
   "outputs": [],
   "source": [
    "def human(mask, guessed, **kwargs):\n",
    "    \"\"\"\n",
    "    This is a simple function for manual play.\n",
    "    \"\"\"\n",
    "    print('Enter your guess:')\n",
    "    return input().lower().strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bgj3i3sz5rPA"
   },
   "source": [
    "If you want to play hangman interactively, please set `interactive` to True. When submitting your solution, set to False so we can automatically run the whole notebook using `Run All`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T7C6Qv5E5rPB"
   },
   "outputs": [],
   "source": [
    "interactive = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M7HcWRc85rPF"
   },
   "source": [
    "<b>For your testing:</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zYp64Mud5rPG"
   },
   "source": [
    "You can play the game interactively using the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 731
    },
    "colab_type": "code",
    "id": "tqblOY_u5rPH",
    "outputId": "a6f4548d-ecc6-42a4-ae2e-337befc00aa9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting hangman game. Target is _ _ _ _ _ _ _ _ length 8\n",
      "You have 8 attempts remaining.\n",
      "Enter your guess:\n",
      "w\n",
      "Guess is w\n",
      "Good guess: w _ _ _ _ _ _ _\n",
      "You have 8 attempts remaining.\n",
      "Enter your guess:\n",
      "h\n",
      "Guess is h\n",
      "Good guess: w h _ _ _ _ _ _\n",
      "You have 8 attempts remaining.\n",
      "Enter your guess:\n",
      "a\n",
      "Guess is a\n",
      "Good guess: w h a _ _ _ _ _\n",
      "You have 8 attempts remaining.\n",
      "Enter your guess:\n",
      "t\n",
      "Guess is t\n",
      "Good guess: w h a t _ _ _ _\n",
      "You have 8 attempts remaining.\n",
      "Enter your guess:\n",
      "e\n",
      "Guess is e\n",
      "Good guess: w h a t e _ e _\n",
      "You have 8 attempts remaining.\n",
      "Enter your guess:\n",
      "v\n",
      "Guess is v\n",
      "Good guess: w h a t e v e _\n",
      "You have 8 attempts remaining.\n",
      "Enter your guess:\n",
      "r\n",
      "Guess is r\n",
      "Good guess: w h a t e v e r\n",
      "Congratulations, you won.\n"
     ]
    }
   ],
   "source": [
    "if interactive:\n",
    "  \n",
    "    hangman('whatever', human, 8, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vte4ryru5rPK"
   },
   "source": [
    "## 1. Preparing Test Set and Training Set (1 mark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "UMuppBB25rPL"
   },
   "source": [
    "<b>Instructions</b>: We will be using the words occurring in the *Brown* corpus for *training* an artificial intelligence guessing algorithm, and for *evaluating* the quality of the algorithm. Note that we are intentionally making the hangman game hard, as the AI will need to cope with test words that it has not seen before, hence it will need to learn generalisable patterns of characters to make reasonable predictions.\n",
    "\n",
    "Your first task is to compute the unique word types occurring in the *Brown* corpus, using `nltk.corpus.Brown` and the `words` method, selecting only words that are entirely comprised of alphabetic characters, and lowercasing the words. Finally, randomly shuffle (`numpy.random.shuffle`) this collection of word types, and split them into disjoint training and testing sets. The test set should contain 1000 word types, and the rest should be in the training set. Your code should print the sizes of the training and test sets.\n",
    "\n",
    "Feel free to test your own Hangman performance using `hangman(numpy.random.choice(test_set), human, 8, True)`. It is surprisingly difficult (and addictive)!\n",
    "\n",
    "(1 mark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "eciFtB5v5rPL",
    "outputId": "c4a25107-22da-4650-a52c-879dffc24c2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40234\n",
      "1000\n",
      "39234\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "# word_set stores all the unique word types of the Brown corpus\n",
    "word_set = []\n",
    "# test_set stores 1000 word types for testing purpose\n",
    "test_set = []\n",
    "# training_set stores the rest word types for training purpose\n",
    "training_set = []\n",
    "\n",
    "###\n",
    "# Your answer BEGINS HERE\n",
    "###\n",
    "# storing word types in dataset that are alphabetic and lowercased\n",
    "dataset = nltk.corpus.brown.words()\n",
    "for word in dataset:\n",
    "    if word.isalpha():\n",
    "        term =word.lower()\n",
    "        if term not in word_set:\n",
    "            word_set.append(term)\n",
    "np.random.shuffle(word_set)\n",
    "#from start to 1000 word types of the word set\n",
    "test_set=word_set[:1000]\n",
    "#from 1000 to rest of word types of the word set\n",
    "training_set=word_set[1000:]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###\n",
    "# Your answer ENDS HERE\n",
    "###\n",
    "\n",
    "print(len(word_set))\n",
    "print(len(test_set))\n",
    "print(len(training_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6FDKu5cC5rPO"
   },
   "source": [
    "<b>For your testing:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kFdU21W15rPO"
   },
   "outputs": [],
   "source": [
    "assert(len(word_set) > 35000 and len(word_set) < 45000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sFjJi2BR5rPR"
   },
   "outputs": [],
   "source": [
    "assert(len(test_set) == 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cFoLMcag5rPU"
   },
   "outputs": [],
   "source": [
    "assert(len(training_set) + len(test_set) == len(word_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "05KyvrcZ5rPW",
    "outputId": "861a3c28-a79b-4162-b4cd-f06a7b2d647d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting hangman game. Target is _ _ _ _ _ _ _ _ _ _ _ length 11\n",
      "You have 8 attempts remaining.\n",
      "Enter your guess:\n",
      "d\n",
      "Guess is d\n",
      "Sorry, try again.\n",
      "You have 7 attempts remaining.\n",
      "Enter your guess:\n",
      "a\n",
      "Guess is a\n",
      "Sorry, try again.\n",
      "You have 6 attempts remaining.\n",
      "Enter your guess:\n",
      "i\n",
      "Guess is i\n",
      "Good guess: i _ _ _ _ _ _ _ i _ _\n",
      "You have 6 attempts remaining.\n",
      "Enter your guess:\n",
      "n\n",
      "Guess is n\n",
      "Good guess: i n _ _ n _ _ _ i _ _\n",
      "You have 6 attempts remaining.\n",
      "Enter your guess:\n",
      "o\n",
      "Guess is o\n",
      "Good guess: i n _ o n _ _ _ i _ _\n",
      "You have 6 attempts remaining.\n",
      "Enter your guess:\n",
      "m\n",
      "Guess is m\n",
      "Sorry, try again.\n",
      "You have 5 attempts remaining.\n",
      "Enter your guess:\n",
      "r\n",
      "Guess is r\n",
      "Good guess: i n _ o n _ r _ i _ _\n",
      "You have 5 attempts remaining.\n",
      "Enter your guess:\n",
      "j\n",
      "Guess is j\n",
      "Sorry, try again.\n",
      "You have 4 attempts remaining.\n",
      "Enter your guess:\n",
      "k\n",
      "Guess is k\n",
      "Sorry, try again.\n",
      "You have 3 attempts remaining.\n",
      "Enter your guess:\n",
      "r\n",
      "Guess is r\n",
      "Already guessed this before.\n",
      "You have 2 attempts remaining.\n",
      "Enter your guess:\n",
      "e\n",
      "Guess is e\n",
      "Sorry, try again.\n",
      "You have 1 attempts remaining.\n",
      "Enter your guess:\n",
      "i\n",
      "Guess is i\n",
      "Already guessed this before.\n",
      "Out of guesses. The word was incongruity\n"
     ]
    }
   ],
   "source": [
    "if interactive:\n",
    "  \n",
    "  \n",
    "    hangman(np.random.choice(test_set), human, 8, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tKP06RR35rPX"
   },
   "source": [
    "## 2. Simple Guesser: Random Guessing (1 mark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6Xipelr_5rPY"
   },
   "source": [
    "<b>Instructions</b>: To set a baseline, your first *AI* attempt will be a trivial random method. For this you should implement a guessing method, similar to the `human` method above, i.e., using the same input arguments and returning a character. Your method should randomly choose a character from the range `'a'...'z'` after excluding the characters that have already been guessed in the current game (all subsequent AI approaches should also exclude previous guesses). You might want to use `numpy.random.choice` for this purpose.\n",
    "\n",
    "To help you measure the performance of this (and later) guesser, a `test_guesser` method that takes a guesser and measures the average number of incorrect guesses made over all the words in the `test_set` is provided to you. \n",
    "\n",
    "(1 mark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aIpsjf0X5rPY"
   },
   "outputs": [],
   "source": [
    "def test_guesser(guesser, test=test_set):\n",
    "    \"\"\"\n",
    "        This function takes a guesser and measures the average number of incorrect guesses made over all the words in the test_set. \n",
    "    \"\"\"\n",
    "    total = 0\n",
    "    for word in test:\n",
    "        total += hangman(word, guesser, 26, False)\n",
    "    return total / float(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 748
    },
    "colab_type": "code",
    "id": "srGsXSPL5rPb",
    "outputId": "05e20a3e-f4b4-4223-f4aa-73cd4e5f09a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting hangman game. Target is _ _ _ length 3\n",
      "You have 10 attempts remaining.\n",
      "Guess is d\n",
      "Sorry, try again.\n",
      "You have 9 attempts remaining.\n",
      "Guess is i\n",
      "Sorry, try again.\n",
      "You have 8 attempts remaining.\n",
      "Guess is m\n",
      "Sorry, try again.\n",
      "You have 7 attempts remaining.\n",
      "Guess is n\n",
      "Sorry, try again.\n",
      "You have 6 attempts remaining.\n",
      "Guess is p\n",
      "Sorry, try again.\n",
      "You have 5 attempts remaining.\n",
      "Guess is z\n",
      "Sorry, try again.\n",
      "You have 4 attempts remaining.\n",
      "Guess is j\n",
      "Sorry, try again.\n",
      "You have 3 attempts remaining.\n",
      "Guess is a\n",
      "Sorry, try again.\n",
      "You have 2 attempts remaining.\n",
      "Guess is o\n",
      "Good guess: _ _ o\n",
      "You have 2 attempts remaining.\n",
      "Guess is h\n",
      "Sorry, try again.\n",
      "You have 1 attempts remaining.\n",
      "Guess is c\n",
      "Sorry, try again.\n",
      "Out of guesses. The word was leo\n",
      "\n",
      "Average number of incorrect guesses:  16.645\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import random\n",
    "\n",
    "def random_guesser(mask, guessed, **kwargs):\n",
    "    \"\"\"\n",
    "        This function implements a random guesser. It returns the random guess. \n",
    "    \"\"\"\n",
    "    ###\n",
    "    # Your answer BEGINS HERE\n",
    "    ###\n",
    "    #alphabet_set stores all the lowercase alphabets and letter is chosen randomly from the set\n",
    "    alphabet_set = string.ascii_lowercase\n",
    "    letter=random.choice(alphabet_set)\n",
    "    #if letter is not in guessed then letter is returned otherwise random guesser is called\n",
    "    if letter not in guessed:\n",
    "        return letter\n",
    "    else:\n",
    "        return random_guesser(mask, guessed, **kwargs)\n",
    "\n",
    "    ###\n",
    "    # Your answer ENDS HERE\n",
    "    ###\n",
    "\n",
    "# uncomment to run a single hangman game with output shown (useful for debugging)\n",
    "hangman(np.random.choice(test_set), random_guesser, 10, True)\n",
    "\n",
    "result = test_guesser(random_guesser)\n",
    "print()\n",
    "print(\"Average number of incorrect guesses: \", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WcqZRL8N5rPc"
   },
   "source": [
    "<b>For your testing:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bbhxgs4-5rPc"
   },
   "outputs": [],
   "source": [
    "assert(result > 10 and result < 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WFBaefAQ5rPe"
   },
   "source": [
    "## 3. Your First AI Guesser: Unigram Guesser (1 mark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xXmnEa605rPf"
   },
   "source": [
    "**Instructions:** As your first real AI, you should train a *unigram* model over the training set.  This requires you to find the frequencies of characters over all training words. Using this model, you should write a guesser that returns the character with the highest probability. Remember to exclude already guessed characters. \n",
    "\n",
    "Hint: It should be much lower than random guessing.\n",
    "\n",
    "(1 mark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 748
    },
    "colab_type": "code",
    "id": "L2UukTSc5rPf",
    "outputId": "74406c6d-69f2-4b6d-fae6-c0ae5da11f24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting hangman game. Target is _ _ _ _ _ length 5\n",
      "You have 10 attempts remaining.\n",
      "Guess is e\n",
      "Sorry, try again.\n",
      "You have 9 attempts remaining.\n",
      "Guess is i\n",
      "Sorry, try again.\n",
      "You have 8 attempts remaining.\n",
      "Guess is a\n",
      "Sorry, try again.\n",
      "You have 7 attempts remaining.\n",
      "Guess is s\n",
      "Good guess: _ _ s _ s\n",
      "You have 7 attempts remaining.\n",
      "Guess is n\n",
      "Sorry, try again.\n",
      "You have 6 attempts remaining.\n",
      "Guess is r\n",
      "Sorry, try again.\n",
      "You have 5 attempts remaining.\n",
      "Guess is t\n",
      "Good guess: _ _ s t s\n",
      "You have 5 attempts remaining.\n",
      "Guess is o\n",
      "Good guess: _ o s t s\n",
      "You have 5 attempts remaining.\n",
      "Guess is l\n",
      "Sorry, try again.\n",
      "You have 4 attempts remaining.\n",
      "Guess is c\n",
      "Sorry, try again.\n",
      "You have 3 attempts remaining.\n",
      "Guess is d\n",
      "Sorry, try again.\n",
      "You have 2 attempts remaining.\n",
      "Guess is u\n",
      "Sorry, try again.\n",
      "You have 1 attempts remaining.\n",
      "Guess is m\n",
      "Sorry, try again.\n",
      "Out of guesses. The word was hosts\n",
      "\n",
      "Average number of incorrect guesses:  10.337\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "# unigram_counts stores the frequencies of characters over all training words\n",
    "\n",
    "\n",
    "###\n",
    "# Your answer BEGINS HERE\n",
    "###\n",
    "#loop through all characters of the training set\n",
    "unigram_counts = Counter()\n",
    "for word in training_set:\n",
    "    for letter in word:\n",
    "        unigram_counts[letter]+=1\n",
    "\n",
    "###\n",
    "# Your answer ENDS HERE\n",
    "###\n",
    "\n",
    "prob_count = Counter()\n",
    "\n",
    "def unigram_guesser(mask, guessed, unigram_counts=unigram_counts):\n",
    "    \"\"\"\n",
    "        This function implements a unigram guesser. It returns a guess based on the unigram model. \n",
    "    \"\"\"\n",
    "    ###\n",
    "    # Your answer BEGINS HERE\n",
    "    ###\n",
    "    #sums the unigram counts and calculates the probability for all letters\n",
    "    sum_count = float(sum(unigram_counts.values()))\n",
    "    for i in range(len(unigram_counts)):\n",
    "        prob_count[unigram_counts.most_common()[i][0]] = unigram_counts.most_common()[i][1]/sum_count\n",
    "    #selects the most common letter based on probability and returns if not guessed\n",
    "    i=0\n",
    "    letter=prob_count.most_common()[i][0]\n",
    "    while(letter in guessed):\n",
    "        i+=1\n",
    "        letter=prob_count.most_common()[i][0]\n",
    "    \n",
    "    return letter\n",
    "    \n",
    "    ###\n",
    "    # Your answer ENDS HERE\n",
    "    ###\n",
    "\n",
    "hangman(np.random.choice(test_set), unigram_guesser, 10, True)\n",
    "\n",
    "result = test_guesser(unigram_guesser)\n",
    "print()\n",
    "print(\"Average number of incorrect guesses: \", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3ck8S0rDds4_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1A7NqRUy5rPh"
   },
   "source": [
    "<b>For your testing:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vMOk2uRG5rPi"
   },
   "outputs": [],
   "source": [
    "assert(result > 5 and result < 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eg9-zi8g5rPj"
   },
   "source": [
    "## 4. Your Second AI Guesser: Length-based Unigram Guesser (1 mark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PFX4JIxp5rPj"
   },
   "source": [
    "**Instructions:** The length of the secret word is an important clue that we might exploit. Different length words tend to have different distributions over characters, e.g., short words are less likely to have suffixes or prefixes. You should incorporate this idea by conditioning the unigram model on the length of the secret word, i.e., having a *different* unigram model for each length of the words. You will need to be a little careful at test time, to be robust to the (unlikely) situation that you encounter a word length that you didn't see in training. You need to decide on how to handle this situation.\n",
    "\n",
    "(1 mark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "colab_type": "code",
    "id": "6QgSR3ih5rPk",
    "outputId": "279beec4-8b82-4e67-e77a-4f8ee349a557",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22]\n",
      "\n",
      "{1: {'r': 1.0, 'b': 1.0, 'x': 1.0, 'f': 1.0, 'u': 1.0, 'j': 1.0, 'w': 1.0, 'y': 1.0, 'l': 1.0, 'n': 1.0, 'h': 1.0, 'z': 1.0, 'o': 1.0, 'v': 1.0, 'i': 1.0, 'm': 1.0, 'k': 1.0, 'g': 1.0, 'q': 1.0, 'd': 1.0, 'p': 1.0, 's': 1.0, 'a': 1.0, 'c': 1.0, 'e': 1.0, 't': 1.0}, 2: {'s': 18.0, 'w': 7.0, 'e': 21.0, 'n': 10.0, 'v': 7.0, 'h': 11.0, 't': 9.0, 'i': 16.0, 'r': 9.0, 'k': 5.0, 'u': 8.0, 'o': 17.0, 'b': 8.0, 'y': 6.0, 'a': 21.0, 'd': 9.0, 'x': 3.0, 'm': 19.0, 'g': 6.0, 'p': 11.0, 'l': 13.0, 'q': 2.0, 'f': 10.0, 'c': 10.0, 'j': 5.0, 'z': 1.0}, 3: {'n': 115.0, 'u': 101.0, 't': 115.0, 'e': 197.0, 'l': 77.0, 'i': 127.0, 'r': 100.0, 'p': 100.0, 'o': 181.0, 'v': 24.0, 's': 112.0, 'b': 92.0, 'a': 235.0, 'w': 73.0, 'm': 103.0, 'h': 78.0, 'd': 97.0, 'q': 6.0, 'f': 52.0, 'g': 76.0, 'y': 78.0, 'c': 69.0, 'k': 31.0, 'z': 10.0, 'j': 29.0, 'x': 23.0}, 4: {'s': 696.0, 'l': 559.0, 'a': 875.0, 'm': 300.0, 'g': 222.0, 'i': 543.0, 'f': 171.0, 't': 490.0, 'b': 261.0, 'r': 522.0, 'o': 682.0, 'k': 229.0, 'y': 183.0, 'd': 356.0, 'n': 473.0, 'j': 61.0, 'x': 36.0, 'z': 46.0, 'u': 345.0, 'e': 899.0, 'c': 254.0, 'w': 189.0, 'h': 289.0, 'p': 282.0, 'v': 97.0, 'q': 8.0}, 5: {'w': 302.0, 'h': 588.0, 'i': 1158.0, 'n': 1040.0, 'e': 2193.0, 'd': 774.0, 'a': 1824.0, 'v': 236.0, 'f': 344.0, 's': 1824.0, 'r': 1365.0, 'g': 458.0, 'm': 569.0, 'o': 1328.0, 'b': 497.0, 'l': 1189.0, 'u': 667.0, 'p': 522.0, 'k': 375.0, 't': 1078.0, 'y': 546.0, 'j': 79.0, 'c': 706.0, 'z': 88.0, 'x': 66.0, 'q': 29.0}, 6: {'b': 779.0, 'a': 2683.0, 'n': 1990.0, 'k': 450.0, 'e': 4244.0, 'd': 1631.0, 'g': 889.0, 'i': 2042.0, 'o': 1974.0, 'v': 393.0, 's': 2590.0, 'y': 705.0, 'h': 873.0, 'l': 1948.0, 'f': 502.0, 't': 1844.0, 'm': 935.0, 'c': 1059.0, 'x': 95.0, 'r': 2543.0, 'w': 429.0, 'u': 1153.0, 'z': 121.0, 'p': 845.0, 'j': 106.0, 'q': 51.0}, 7: {'b': 940.0, 'e': 5327.0, 'd': 2046.0, 'f': 661.0, 'a': 3554.0, 's': 3479.0, 't': 2670.0, 'c': 1668.0, 'o': 2489.0, 'n': 3031.0, 'l': 2483.0, 'm': 1240.0, 'i': 3325.0, 'u': 1496.0, 'w': 525.0, 'h': 1095.0, 'r': 3411.0, 'g': 1485.0, 'y': 740.0, 'v': 463.0, 'p': 1236.0, 'z': 154.0, 'j': 95.0, 'k': 570.0, 'q': 82.0, 'x': 108.0}, 8: {'e': 5588.0, 'x': 108.0, 't': 2911.0, 'n': 3491.0, 'd': 2206.0, 'm': 1304.0, 'i': 3895.0, 'g': 1525.0, 'a': 3680.0, 'r': 3482.0, 'o': 2778.0, 'c': 1937.0, 's': 3693.0, 'f': 714.0, 'l': 2622.0, 'u': 1570.0, 'v': 533.0, 'b': 860.0, 'h': 1169.0, 'w': 473.0, 'p': 1230.0, 'y': 719.0, 'k': 511.0, 'q': 83.0, 'z': 114.0, 'j': 84.0}, 9: {'a': 3457.0, 'r': 3262.0, 'm': 1242.0, 'c': 1921.0, 'h': 1022.0, 'i': 3921.0, 's': 3460.0, 'u': 1444.0, 'n': 3443.0, 'b': 756.0, 'o': 2611.0, 'd': 1871.0, 'e': 5440.0, 'g': 1365.0, 't': 3064.0, 'l': 2329.0, 'p': 1167.0, 'y': 653.0, 'w': 375.0, 'v': 537.0, 'k': 376.0, 'z': 131.0, 'x': 127.0, 'f': 590.0, 'j': 69.0, 'q': 88.0}, 10: {'m': 1061.0, 'i': 3628.0, 'l': 1961.0, 'e': 4356.0, 'n': 3106.0, 'u': 1292.0, 'c': 1686.0, 'o': 2401.0, 'v': 445.0, 't': 2803.0, 'f': 461.0, 'a': 2805.0, 's': 2921.0, 'd': 1419.0, 'g': 1102.0, 'r': 2683.0, 'y': 558.0, 'p': 1079.0, 'j': 55.0, 'k': 180.0, 'h': 832.0, 'w': 207.0, 'b': 621.0, 'x': 91.0, 'q': 66.0, 'z': 111.0}, 11: {'r': 1930.0, 'e': 2959.0, 'c': 1240.0, 'o': 1707.0, 'm': 737.0, 'n': 2270.0, 'd': 811.0, 'h': 523.0, 'y': 416.0, 's': 2001.0, 'u': 858.0, 't': 2157.0, 'f': 293.0, 'a': 2034.0, 'i': 2760.0, 'p': 774.0, 'v': 293.0, 'l': 1325.0, 'b': 423.0, 'g': 634.0, 'x': 74.0, 'q': 46.0, 'z': 71.0, 'k': 137.0, 'w': 121.0, 'j': 26.0}, 12: {'c': 894.0, 'o': 1228.0, 'n': 1540.0, 'u': 584.0, 'r': 1268.0, 'e': 1903.0, 't': 1467.0, 'l': 972.0, 'y': 300.0, 's': 1302.0, 'i': 1904.0, 'm': 518.0, 'a': 1415.0, 'z': 71.0, 'd': 501.0, 'p': 554.0, 'h': 384.0, 'g': 395.0, 'v': 194.0, 'w': 52.0, 'b': 256.0, 'q': 37.0, 'x': 41.0, 'j': 17.0, 'f': 196.0, 'k': 55.0}, 13: {'p': 364.0, 'r': 746.0, 'e': 1047.0, 'o': 836.0, 's': 792.0, 'i': 1277.0, 't': 965.0, 'n': 1020.0, 'a': 903.0, 'l': 542.0, 'c': 566.0, 'u': 328.0, 'b': 139.0, 'm': 343.0, 'g': 244.0, 'y': 205.0, 'k': 26.0, 'h': 208.0, 'd': 262.0, 'f': 116.0, 'x': 34.0, 'q': 18.0, 'v': 117.0, 'z': 36.0, 'w': 23.0, 'j': 10.0}, 14: {'o': 458.0, 'r': 397.0, 'c': 305.0, 'h': 128.0, 'e': 564.0, 's': 463.0, 't': 522.0, 'a': 463.0, 'i': 711.0, 'n': 541.0, 'v': 63.0, 'l': 332.0, 'g': 118.0, 'j': 3.0, 'u': 169.0, 'd': 148.0, 'f': 63.0, 'm': 158.0, 'p': 178.0, 'y': 118.0, 'b': 69.0, 'x': 13.0, 'z': 35.0, 'w': 10.0, 'q': 8.0, 'k': 11.0}, 15: {'d': 71.0, 'i': 401.0, 'f': 25.0, 'e': 246.0, 'r': 198.0, 'n': 274.0, 't': 282.0, 'a': 235.0, 'g': 52.0, 'o': 251.0, 'z': 18.0, 's': 209.0, 'c': 167.0, 'l': 163.0, 'u': 70.0, 'h': 70.0, 'p': 110.0, 'y': 76.0, 'm': 72.0, 'v': 20.0, 'w': 5.0, 'x': 8.0, 'b': 24.0, 'j': 1.0, 'k': 8.0, 'q': 4.0}, 16: {'r': 94.0, 'e': 104.0, 's': 89.0, 'p': 46.0, 'o': 105.0, 'n': 110.0, 'i': 169.0, 'b': 11.0, 'l': 91.0, 't': 132.0, 'y': 33.0, 'h': 36.0, 'u': 32.0, 'a': 110.0, 'c': 64.0, 'g': 22.0, 'd': 24.0, 'm': 35.0, 'z': 10.0, 'f': 8.0, 'v': 6.0, 'x': 6.0, 'k': 4.0, 'w': 1.0, 'q': 2.0}, 17: {'c': 38.0, 'o': 57.0, 'n': 68.0, 't': 81.0, 'r': 64.0, 'a': 72.0, 'd': 23.0, 'i': 94.0, 's': 43.0, 'h': 24.0, 'e': 69.0, 'm': 25.0, 'y': 18.0, 'l': 43.0, 'u': 18.0, 'z': 9.0, 'b': 5.0, 'f': 3.0, 'g': 12.0, 'v': 4.0, 'p': 25.0, 'k': 1.0, 'x': 1.0, 'w': 1.0, 'j': 1.0}, 18: {'d': 12.0, 'i': 48.0, 'e': 37.0, 't': 44.0, 'h': 13.0, 'y': 10.0, 'l': 23.0, 's': 35.0, 'b': 2.0, 'r': 34.0, 'o': 33.0, 'c': 24.0, 'm': 9.0, 'p': 14.0, 'n': 29.0, 'a': 25.0, 'u': 8.0, 'k': 2.0, 'g': 6.0, 'f': 4.0, 'z': 1.0, 'v': 1.0}, 19: {'h': 2.0, 'y': 1.0, 'p': 3.0, 'o': 18.0, 'a': 11.0, 'd': 3.0, 'r': 9.0, 'e': 8.0, 'n': 14.0, 'c': 7.0, 't': 13.0, 'i': 15.0, 's': 7.0, 'm': 3.0, 'g': 3.0, 'l': 7.0, 'u': 5.0, 'f': 2.0, 'z': 2.0}, 20: {'i': 5.0, 'n': 3.0, 's': 1.0, 't': 4.0, 'u': 1.0, 'o': 2.0, 'a': 2.0, 'l': 1.0, 'z': 1.0}, 21: {'p': 3.0, 's': 3.0, 'y': 1.0, 'c': 4.0, 'h': 3.0, 'o': 6.0, 'a': 3.0, 'r': 3.0, 'm': 3.0, 'l': 3.0, 'g': 1.0, 'i': 3.0, 'u': 1.0, 'n': 1.0, 'e': 3.0, 't': 1.0}, 22: {'a': 2.0, 'l': 3.0, 'k': 1.0, 'y': 1.0, 'b': 1.0, 'e': 4.0, 'n': 3.0, 'z': 1.0, 's': 2.0, 'u': 1.0, 'f': 1.0, 'o': 1.0, 't': 1.0}}\n",
      "Starting hangman game. Target is _ _ _ length 3\n",
      "You have 10 attempts remaining.\n",
      "Guess is e\n",
      "Sorry, try again.\n",
      "You have 9 attempts remaining.\n",
      "Guess is i\n",
      "Sorry, try again.\n",
      "You have 8 attempts remaining.\n",
      "Guess is n\n",
      "Good guess: _ n n\n",
      "You have 8 attempts remaining.\n",
      "Guess is s\n",
      "Sorry, try again.\n",
      "You have 7 attempts remaining.\n",
      "Guess is a\n",
      "Good guess: a n n\n",
      "Congratulations, you won.\n",
      "\n",
      "Average number of incorrect guesses:  10.342\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from string import ascii_lowercase\n",
    "# unigram_counts_by_length stores a dictionary, mapping word length to the frequencies of characters of words with that word length\n",
    "unigram_counts_by_length = defaultdict(Counter)\n",
    "\n",
    "###\n",
    "# Your answer BEGINS HERE\n",
    "###\n",
    "#function to calculate unigram probability\n",
    "def get_unigram_prob(length = -1):\n",
    "    unigram_probability = {}\n",
    "    letter_freq = {}\n",
    "    for word in training_set:\n",
    "        if length == -1 or len(word)==length:\n",
    "            for char in word:\n",
    "                letter_freq[char] = float(letter_freq.get(char,0)+1)\n",
    "    \n",
    "    totalfreq = float(sum(letter_freq.values()))\n",
    "    \n",
    "    for key, value in sorted(letter_freq.items(), key=lambda kv: (kv[1], kv[0])):\n",
    "        unigram_probability[key] = float(value/totalfreq)\n",
    "    return unigram_probability\n",
    "\n",
    "#function to calculate unigram frequency\n",
    "def getUnigramFreq(Length):\n",
    "    freq = {}\n",
    "    for word in training_set:\n",
    "        if len(word)== Length:\n",
    "            for char in word:\n",
    "                freq[char] = float(freq.get(char,0)+1)\n",
    "    return freq\n",
    "\n",
    "unigram_models = []\n",
    "unigram_dict ={}\n",
    "max_wordlength = 0;\n",
    "for word in training_set:\n",
    "    if len(word) > max_wordlength:\n",
    "        max_wordlength = len(word)\n",
    "        \n",
    "for wordlength in range(max_wordlength+1):\n",
    "    if wordlength!=0:\n",
    "        unigram_models.append(get_unigram_prob(length = wordlength))\n",
    "        unigram_dict[wordlength]=getUnigramFreq(wordlength)\n",
    "\n",
    "unigram_models.append(get_unigram_prob())       \n",
    "unigram_counts_by_length = unigram_dict\n",
    "sorted_alphabets = []\n",
    "###\n",
    "# Your answer ENDS HERE\n",
    "###\n",
    "\n",
    "\n",
    "lengths = sorted(unigram_counts_by_length.keys())\n",
    "print(lengths)\n",
    "max_length = lengths[-1] + 1\n",
    "print()\n",
    "print(unigram_counts_by_length)\n",
    "\n",
    "if len(word) <= max_wordlen + 1:\n",
    "    for key, value in sorted(unigram_models[len(word)-1].items(), key=lambda kv: (kv[1], kv[0]),reverse = True):\n",
    "        sorted_alphabets.append(key)   \n",
    "else:\n",
    "    for key, value in sorted(unigram_models[-1].items(), key=lambda kv: (kv[1], kv[0]),reverse = True):\n",
    "        sorted_alphabets.append(key)  \n",
    "\n",
    "\n",
    "def unigram_length_guesser(mask, guessed, counts=unigram_counts_by_length):\n",
    "    \"\"\"\n",
    "        This function implements a length-based unigram guesser. It returns a guess based on the length-based unigram model. \n",
    "    \"\"\"\n",
    "    ###\n",
    "    # Your answer BEGINS HERE\n",
    "    ###\n",
    "    \n",
    "    i = 0\n",
    "    #most probable alphabet\n",
    "    letter = sorted_alphabets[0]\n",
    "    while letter in guessed:\n",
    "        letter = sorted_prob_alphabets[i]\n",
    "        i = i+1\n",
    "    return letter\n",
    "    \n",
    "    \n",
    "    \n",
    "    ###\n",
    "    # Your answer ENDS HERE\n",
    "    ###\n",
    "\n",
    "hangman(np.random.choice(test_set), unigram_length_guesser, 10, True)\n",
    "\n",
    "result = test_guesser(unigram_length_guesser)\n",
    "print()\n",
    "print(\"Average number of incorrect guesses: \", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-fPEjkfZ5rPl"
   },
   "source": [
    "<b>For your testing:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "neFxQuYA5rPl"
   },
   "outputs": [],
   "source": [
    "assert(result > 5 and result < 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OMVnjpYZ5rPm"
   },
   "source": [
    "## 5. Your Third AI Guesser: Bigram Guesser (1 mark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OJ-ceCBa5rPm"
   },
   "source": [
    "**Instructions:** Now for the next challenge, using a *bigram* language model over characters. The order of characters is obviously important, yet this wasn't incorporated in any of the above models. Knowing that the word has the sequence `n _ s s` is a pretty strong clue that the missing character might be `e`. Similarly the distribution over characters that start or end a word are highly biased (e.g., toward common prefixes and suffixes, like *un-*, *-ed* and *-ly*).\n",
    "\n",
    "You should develop a *bigram* language model over characters, train this over the training words (being careful to handle the start of each word properly, e.g., by padding with a sentinel symbol `$`.) You should use *linear interpolation* to smooth between the higher order and lower order models, and you will have to decide how to weight each component (be reminded that all probabilities should sum to 1).\n",
    "\n",
    "Your bigram guesser should apply your language model to each blank position in the secret word by using the left context as is known. E.g., in the partial word `$ _ e c _ e _ _` we know the left context for the first three blanks, but have no known left context for the last blank. Using a bigram language model, we are able to apply it to the first three blanks only. You should then select the character with the highest probability of predicting the most number of correct entries over the blanks. \n",
    "\n",
    "Do you see any improvement over the unigram guessers above?\n",
    "\n",
    "(1 mark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wZEoVLfZ5rPm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting hangman game. Target is _ _ _ _ _ _ _ length 7\n",
      "You have 10 attempts remaining.\n",
      "Guess is e\n",
      "Sorry, try again.\n",
      "You have 9 attempts remaining.\n",
      "Guess is s\n",
      "Sorry, try again.\n",
      "You have 8 attempts remaining.\n",
      "Guess is i\n",
      "Good guess: _ _ _ _ i _ _\n",
      "You have 8 attempts remaining.\n",
      "Guess is n\n",
      "Good guess: _ _ _ _ i n _\n",
      "You have 8 attempts remaining.\n",
      "Guess is a\n",
      "Good guess: _ a _ _ i n _\n",
      "You have 8 attempts remaining.\n",
      "Guess is t\n",
      "Sorry, try again.\n",
      "You have 7 attempts remaining.\n",
      "Guess is c\n",
      "Sorry, try again.\n",
      "You have 6 attempts remaining.\n",
      "Guess is d\n",
      "Good guess: _ a _ d i n _\n",
      "You have 6 attempts remaining.\n",
      "Guess is g\n",
      "Good guess: _ a _ d i n g\n",
      "You have 6 attempts remaining.\n",
      "Guess is r\n",
      "Sorry, try again.\n",
      "You have 5 attempts remaining.\n",
      "Guess is l\n",
      "Good guess: _ a l d i n g\n",
      "You have 5 attempts remaining.\n",
      "Guess is p\n",
      "Sorry, try again.\n",
      "You have 4 attempts remaining.\n",
      "Guess is b\n",
      "Good guess: b a l d i n g\n",
      "Congratulations, you won.\n",
      "\n",
      "Average number of incorrect guesses:  8.657\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "# Your answer BEGINS HERE\n",
    "###\n",
    "bigram_counts = defaultdict(Counter) \n",
    "\n",
    "def convert_word(word):\n",
    "    return '^' + word\n",
    "\n",
    "ngram_counts = []\n",
    "ngram_counts.append(Counter()) # unigram_counts\n",
    "ngram_counts.append(bigram_counts)  # bigram_counts\n",
    "for word in training_set:\n",
    "    word = convert_word(word)\n",
    "    for i in range(1, len(word)):\n",
    "        ngram_counts[0][word[i]] += 1  #unigram_counts increment\n",
    "        if i >= 1:\n",
    "            ngram_counts[1][word[i-1]][word[i]] += 1  #bigram_counts increment\n",
    "\n",
    "\n",
    "#interploation function\n",
    "def get_char_prob_interp(prev_chars, char, n_gram, ngram_counts, lambdas):\n",
    "    interp_n_gram_counts = [0] * 5\n",
    "    for i in range(n_gram, 0, -1):\n",
    "        if i != 1:\n",
    "            char_i_gram_count = ngram_counts[i-1][prev_chars[-(i-1):]][char]\n",
    "            prev_chars_count = float( sum( ngram_counts[i-1][prev_chars[-(i-1):]].values()) + 1e-6)\n",
    "            interp_n_gram_counts[i-1] = char_i_gram_count / prev_chars_count * lambdas[i-1]\n",
    "        else:\n",
    "            interp_n_gram_counts[i-1] = ngram_counts[i-1][char] / float( sum( n_gram_counts[i-1].values())) * lambdas[i-1]\n",
    "    return math.log(sum(interp_n_gram_counts))\n",
    "    \n",
    "    \n",
    "\n",
    "        \n",
    "\n",
    "###\n",
    "# Your answer ENDS HERE\n",
    "###\n",
    "\n",
    "def bigram_guesser(mask, guessed, counts= ngram_counts, **kwargs): # add extra default arguments if needed\n",
    "    \"\"\"\n",
    "        This function implements a bigram guesser. It returns a guess based on the bigram model using linear interpolation.\n",
    "    \"\"\"\n",
    "    ###\n",
    "    # Your answer BEGINS HERE\n",
    "    ###\n",
    "   \n",
    "    n_gram = 2\n",
    "    labmdas = [[1], [0.1,0.9], [0.01,0.09,0.9], [0.001,0.009,0.09,0.9], [0.0001,0.0009,0.009,0.09,0.9]]\n",
    "    mask = ''.join(mask)\n",
    "    mask = convert_word(mask)\n",
    "    \n",
    "    all_prev_chars = []\n",
    "    prev_chars = \"\"\n",
    "    for char in mask:\n",
    "        if char != '_':\n",
    "            prev_chars += char\n",
    "        else:\n",
    "            all_prev_chars.append(prev_chars)\n",
    "            prev_chars = \"\"\n",
    "            \n",
    "    choices = set(string.ascii_lowercase).difference(guessed)\n",
    "    maxsum_char_prob_interp = float(\"-inf\")\n",
    "    choice = ''\n",
    "    for char in choices:\n",
    "        sum_char_prob_interp = 0\n",
    "        for prev_chars in all_prev_chars:\n",
    "            char_n_gram = n_gram if ((len(prev_chars) + 1) > n_gram) else (len(prev_chars) + 1)\n",
    "            sum_char_prob_interp += get_char_prob_interp(str(prev_chars), char, char_n_gram, n_gram_counts, labmdas[char_n_gram-1])\n",
    "        if sum_char_prob_interp > maxsum_char_prob_interp:\n",
    "            maxsum_char_prob_interp = sum_char_prob_interp\n",
    "            choice = char #best choice\n",
    "    \n",
    "    return choice\n",
    "\n",
    "\n",
    "      \n",
    "   \n",
    "    \n",
    "    ###\n",
    "    # Your answer ENDS HERE\n",
    "    ###\n",
    "\n",
    "hangman(np.random.choice(test_set), bigram_guesser, 10, True)\n",
    "\n",
    "result = test_guesser(bigram_guesser)\n",
    "print()\n",
    "print(\"Average number of incorrect guesses: \", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2OzrNyIq5rPn"
   },
   "source": [
    "<b>For your testing:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4ivJFnlK5rPn"
   },
   "outputs": [],
   "source": [
    "assert(result < 13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IynozKKp5rPp"
   },
   "source": [
    "## 6. Your Own AI Guesser (1 mark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2JG6fIM55rPp"
   },
   "source": [
    "**Instructions:** You should try to develop a more effective AI, `my_ai_guesser`, for hangman. Feel free to engage your creativity here! Possibilities include better conditioning on the length of the word, fancier smoothing methods, and using ngram models. Ensure you report the test performance of your guesser. Have fun!\n",
    "\n",
    "You will be marked based on the explanation of your approach and its accuracy. \n",
    "\n",
    "(1 mark) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MlSsZbmE5rPq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average number of incorrect guesses:  7.49\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "# Your answer BEGINS HERE\n",
    "###\n",
    "#list storing n gram counts\n",
    "ngram_counts = []\n",
    "n_gram_counts.append(Counter())             #unigram_counts\n",
    "n_gram_counts.append(defaultdict(Counter))  #bigram_counts\n",
    "n_gram_counts.append(defaultdict(Counter))  #trigram_counts\n",
    "n_gram_counts.append(defaultdict(Counter))  #quadgram_counts\n",
    "n_gram_counts.append(defaultdict(Counter))  #quingram_counts\n",
    "\n",
    "def convert_word(word):\n",
    "    return '^' + word\n",
    "\n",
    "for word in training_set:\n",
    "    word = convert_word(word)\n",
    "    for i in range(1, len(word)):\n",
    "            n_gram_counts[0][word[i]] += 1   #1-gram increments\n",
    "            if i >= 1:\n",
    "                n_gram_counts[1][word[i-1]][word[i]] += 1  #2-gram increments\n",
    "            if i >= 2:\n",
    "                n_gram_counts[2][word[i-2:i]][word[i]] += 1  #3-gram increments\n",
    "            if i >= 3:\n",
    "                n_gram_counts[3][word[i-3:i]][word[i]] += 1  #4-gram increments\n",
    "            if i >= 4:\n",
    "                n_gram_counts[4][word[i-4:i]][word[i]] += 1  #5-gram increments\n",
    "\n",
    "#interpolation function\n",
    "def get_char_prob_interp(prev_chars, char, n_gram, n_gram_counts, lambdas):\n",
    "    interp_n_gram_counts = [0] * 5\n",
    "    for i in range(n_gram, 0, -1):\n",
    "        if i != 1:\n",
    "            char_i_gram_count = n_gram_counts[i-1][prev_chars[-(i-1):]][char]\n",
    "            prev_chars_count = float( sum( n_gram_counts[i-1][prev_chars[-(i-1):]].values()) + 1e-6)  # sum of ngram counts + 1 * 10**-6\n",
    "            interp_n_gram_counts[i-1] = char_i_gram_count / prev_chars_count * lambdas[i-1]\n",
    "        else:\n",
    "            interp_n_gram_counts[i-1] = n_gram_counts[i-1][char] / float( sum( n_gram_counts[i-1].values())) * lambdas[i-1]\n",
    "    return math.log(sum(interp_n_gram_counts))\n",
    "\n",
    "# 5-gram guesser \n",
    "def my_ai_guesser(mask, guessed, **kwargs):\n",
    "    n_gram = 5 \n",
    "    #lambda values \n",
    "    lambdas = [[1], [0.1,0.9], [0.01,0.09,0.9], [0.001,0.009,0.09,0.9], [0.0001,0.0009,0.009,0.09,0.9]]\n",
    "    mask = ''.join(mask)\n",
    "    mask = convert_word(mask)\n",
    "    \n",
    "    all_prev_chars = []\n",
    "    prev_chars = \"\"\n",
    "    for char in mask:\n",
    "        #previous character is filled\n",
    "        if char != '_':\n",
    "            prev_chars += char\n",
    "        else:\n",
    "            all_prev_chars.append(prev_chars)\n",
    "            prev_chars = \"\"\n",
    "        \n",
    "    choices = set(string.ascii_lowercase).difference(guessed)\n",
    "    #setting max to infinity\n",
    "    maxsum_char_prob_interp = float(\"-inf\")\n",
    "    choice = ''\n",
    "    for char in choices:\n",
    "        sum_char_prob_interp = 0\n",
    "        for prev_chars in all_prev_chars:\n",
    "            char_n_gram = n_gram if ((len(prev_chars) + 1) > n_gram) else (len(prev_chars) + 1)\n",
    "            sum_char_prob_interp += get_char_prob_interp(str(prev_chars), char, char_n_gram, n_gram_counts, lambdas[char_n_gram-1])\n",
    "        if sum_char_prob_interp > maxsum_char_prob_interp:\n",
    "            maxsum_char_prob_interp = sum_char_prob_interp\n",
    "            choice = char #best choice of character\n",
    "    \n",
    "    return choice\n",
    "    \n",
    "    return random_guesser(mask, guessed)\n",
    "\n",
    "###\n",
    "# Your answer ENDS HERE\n",
    "###\n",
    "\n",
    "result = test_guesser(my_ai_guesser)\n",
    "print()\n",
    "print(\"Average number of incorrect guesses: \", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PgilGJ-p5rPr"
   },
   "source": [
    "**Instructions:** Explain your approach and discuss your result below. Please keep it brief.\n",
    "\n",
    "The AI guesser is an extention of the bigram guesser. 5-gram approach have been implemented and interpolation method is used for smoothening the model hence the previous 4 characters have also been taken into consideration to formulate the guesser.Interpolation method combines N-grams of different orders to estimate the probability of an N-gram with zero frequency.The result is better and lesser when compared to the bigram guesser.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "et-cmdrJ5rPr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Homework_3.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
